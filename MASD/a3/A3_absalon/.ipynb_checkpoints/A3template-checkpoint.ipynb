{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Jupyter notebook template for Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the needed modules (feel free to add more as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Allows viewing figures inline in the notebook\n",
    "import numpy as np\n",
    "# Numpy is a library for numerical computation\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlib is a plotting library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template for Exercise 1: Gradient ascent in 2D\n",
    "\n",
    "In this template, you are handed the function $f$ as well as a demo of how to make a contour plot of it using *meshgrid*. Below, you are to implement gradient ascent for this function and visualize the trajectory as you step through the landscape following the gradient during the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function f(x,y) on the 2D plane\n",
    "def f(x,y):\n",
    "#    z1 = 1.5*np.exp(-x**2 - y**2)\n",
    "#    z2 = 2*np.exp(-(x - 1.5)**2 - (y - 1.5)**2)\n",
    "#    z = (z1 + z2)\n",
    "    z = x**2 + y**2 + (x-1)**2 + (y-1)**2\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Contour plot of the function f')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, use meshgrid to make a contour plot of the function in the domain [-2, 4] x [-4, 4]\n",
    "delta = 0.025                                   # width of bin in grid\n",
    "x = np.arange(-2.0, 4.0, delta)                 # x-coordinates of grid nodes\n",
    "y = np.arange(-4.0, 4.0, delta)                 # y-coordinates of grid nodes\n",
    "X, Y = np.meshgrid(x, y)                        # turning the coordinates into a \"meshgrid\" object\n",
    "Z = f(X, Y)                                  # evaluating the function on the grid\n",
    "\n",
    "# Plot the level set of the function (a topographic map) using a contour plot\n",
    "plt.figure()                                    # creating a figure\n",
    "plt.contourf(X, Y, Z)                           # making a contour plot\n",
    "plt.colorbar()                                  # adding a color bar\n",
    "plt.xlabel('x')                                 # adding x- and y- axis labels\n",
    "plt.ylabel('y')\n",
    "plt.title('Contour plot of the function f')  # adding a figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the box below, please implement gradient ascent for the function $f$ defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-16f70180da8e>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-16f70180da8e>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    cur_grad_norm = ##### MISSING\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def f_gradient(x,y):\n",
    "    # This function is meant to compute the gradient of f with respect to (x,y)\n",
    "    # Given: The values x and y\n",
    "    # Return: The gradient grad_f at (x,y)\n",
    "                                            \n",
    "    return grad_f\n",
    "\n",
    "\n",
    "def f_grad_asc():\n",
    "    # A template function for performing gradient ascent over x and y to maximize f\n",
    "    \n",
    "    # Initialize at random\n",
    "    np.random.seed(1) # Fixed seed for reproducibility; please don't change\n",
    "    x,y = np.random.randn(2)\n",
    "    \n",
    "    # Set learning rate (you may want to play with this)\n",
    "    learningrate = 0.00001\n",
    "    \n",
    "    # Setting parameters for convergence check\n",
    "    num_iter = 1                   # This is the variable that will keep track of the number of iterations\n",
    "    convergence = 0                # This is the variable that will keep track of whether we have converged\n",
    "    max_iter = 10000               # We stop the algorithm after this many iterations\n",
    "    tolerance = 0.01               # We conclude convergence when the magnitude of the gradient\n",
    "                                   # is less than the tolerance\n",
    "    \n",
    "    while convergence == 0:\n",
    "        ####################### MISSING PART ############## \n",
    "        # Compute gradient and take a step in the direction it dictates\n",
    "        \n",
    "        \n",
    "        \n",
    "        ####################### MISSING PART ##############        \n",
    "        # Check for convergence -- you need to fill in the computation of the norm of the gradient at the current location\n",
    "        num_iter = num_iter + 1      \n",
    "        cur_grad_norm = ##### MISSING\n",
    "        \n",
    "        if cur_grad_norm < tolerance:\n",
    "            convergence = 1\n",
    "            print('converged')\n",
    "        elif num_iter > max_iter:\n",
    "            convergence = 1 \n",
    "            print('reached maximum nr of iterations')\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-2636e8189e30>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-2636e8189e30>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def f_hessian(x,y):\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def f_hessian(x,y):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, please visualize the steps taken by your gradient ascent for 5 different randomly selected starting points, by plotting the trajectories on top of a contour plot (like the one above) using plt.plot. To randomly select starting points, you can use the function np.random.uniform. See numpy and matplotlib documentation for usage of np.random.uniform and plt.plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template for Exercise 4: Gradient descent for the Netflix Problem\n",
    "Below, you will first load and view the data, and then fill in:\n",
    "* The template function **netflix_gradient**, which computes the gradient of E with respect to a and b\n",
    "* The gradient descent template function **netflix**, where you only need to fill in:\n",
    "    * the update step (initialization and convergence criteria are already taken care of)\n",
    "    * the computation of the gradient magnitude\n",
    "    * you may also want to play with the learning rate\n",
    "* Note: You may want to implement additional functions for debugging purposes\n",
    "\n",
    "Start out by loading and viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and view the incomplete matrix\n",
    "M = np.loadtxt('data/netflix_matrix.txt')\n",
    "# Uncomment if you want to view it\n",
    "#print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netflix_gradient(M, A, B):\n",
    "    # This function is meant to compute the gradient of E with respect to A and B\n",
    "    # Given: * the (6 x 10) numpy array M, whose 0 inputs you want to replace by predictions, \n",
    "    #          and whose nonzero inputs you want to preserve\n",
    "    #        * two variable numpy arrays A (of size 6 x 2) and B (of size 2 x 10), \n",
    "    #          over which you want to optimize to reconstruct the matrix M as well as possible as a product A*B.\n",
    "    # Return: The gradients grad_A and grad_B of the cost function E from the exercise, \n",
    "    #         with respect to a and b, respectively. They should have the same shape as a and b.\n",
    "                                            \n",
    "    return grad_A, grad_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netflix(M):\n",
    "    # A template function for performing gradient descent over A and B to minimize E\n",
    "    # Input: The matrix M to be approximated\n",
    "    people,movies = M.shape\n",
    "    \n",
    "    # Initialize at random\n",
    "    np.random.seed(1) # Fixed seed for reproducibility; please don't change\n",
    "    A = np.random.randn(people,2)\n",
    "    B = np.random.randn(2,movies)\n",
    "    \n",
    "    # Set learning rate (you may want to play with this)\n",
    "    learningrate = 0.00001\n",
    "    \n",
    "    # Setting parameters for convergence check\n",
    "    num_iter = 1                   # This is the variable that will keep track of the number of iterations\n",
    "    convergence = 0                # This is the variable that will keep track of whether we have converged\n",
    "    max_iter = 10000               # We stop the algorithm after this many iterations\n",
    "    tolerance = 0.01               # We conclude convergence when the magnitude of the gradient\n",
    "                                   # is less than the tolerance\n",
    "    \n",
    "    while convergence == 0:\n",
    "        ####################### MISSING PART ############## \n",
    "        # Compute gradient and take a step in the direction it dictates\n",
    "        \n",
    "        \n",
    "        \n",
    "        ####################### MISSING PART ##############        \n",
    "        # Check for convergence -- you need to fill in the computation of the norm of the gradient at the current location\n",
    "        num_iter = num_iter + 1      \n",
    "        cur_grad_norm = ##### MISSING\n",
    "        \n",
    "        if cur_grad_norm < tolerance:\n",
    "            convergence = 1\n",
    "            print('converged')\n",
    "        elif num_iter > max_iter:\n",
    "            convergence = 1 \n",
    "            print('reached maximum nr of iterations')\n",
    "    \n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run your code to return your resulting A, B and A*B, and compare it with M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
