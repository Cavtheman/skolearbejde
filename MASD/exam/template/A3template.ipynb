{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Jupyter notebook template for Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the needed modules (feel free to add more as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Allows viewing figures inline in the notebook\n",
    "import numpy as np\n",
    "# Numpy is a library for numerical computation\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlib is a plotting library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template for Exercise 4: Gradient descent for the Netflix Problem\n",
    "Below, you will first load and view the data, and then fill in:\n",
    "* The template function **netflix_gradient**, which computes the gradient of E with respect to a and b\n",
    "* The gradient descent template function **netflix**, where you only need to fill in:\n",
    "    * the update step (initialization and convergence criteria are already taken care of)\n",
    "    * the computation of the gradient magnitude\n",
    "    * you may also want to play with the learning rate\n",
    "* Note: You may want to implement additional functions for debugging purposes\n",
    "\n",
    "Start out by loading and viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  8.  9.  0.  0.  1.  4.  2.  3.  9.]\n",
      " [ 0.  0. 10.  9. 10.  2.  3.  0.  0.  5.]\n",
      " [10.  9.  0.  8.  0.  0.  0.  2.  1.  3.]\n",
      " [ 1.  0.  2.  0.  0.  9.  8.  9.  0.  0.]\n",
      " [ 0.  1.  1.  0.  2.  0.  9.  0.  7.  0.]\n",
      " [ 2.  1.  0.  0.  1. 10.  0.  9.  0.  8.]]\n"
     ]
    }
   ],
   "source": [
    "# Load and view the incomplete matrix\n",
    "M = np.loadtxt('data/netflix_matrix.txt')\n",
    "# Uncomment if you want to view it\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netflix_gradient(M, A, B):\n",
    "    # This function is meant to compute the gradient of E with respect to A and B\n",
    "    # Given: * the (6 x 10) numpy array M, whose 0 inputs you want to replace by predictions, \n",
    "    #          and whose nonzero inputs you want to preserve\n",
    "    #        * two variable numpy arrays A (of size 6 x 2) and B (of size 2 x 10), \n",
    "    #          over which you want to optimize to reconstruct the matrix M as well as possible as a product A*B.\n",
    "    # Return: The gradients grad_A and grad_B of the cost function E from the exercise, \n",
    "    #         with respect to a and b, respectively. They should have the same shape as a and b.\n",
    "    I = (M > 0) * 1\n",
    "    grad_A = 2*I*(-M+S@B)@(B.T)\n",
    "    \n",
    "    return grad_A, grad_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netflix(M):\n",
    "    # A template function for performing gradient descent over A and B to minimize E\n",
    "    # Input: The matrix M to be approximated\n",
    "    people,movies = M.shape\n",
    "    \n",
    "    # Initialize at random\n",
    "    np.random.seed(1) # Fixed seed for reproducibility; please don't change\n",
    "    A = np.random.randn(people,2)\n",
    "    B = np.random.randn(2,movies)\n",
    "    \n",
    "    # Set learning rate (you may want to play with this)\n",
    "    learningrate = 0.00001\n",
    "    \n",
    "    # Setting parameters for convergence check\n",
    "    num_iter = 1                   # This is the variable that will keep track of the number of iterations\n",
    "    convergence = 0                # This is the variable that will keep track of whether we have converged\n",
    "    max_iter = 10000               # We stop the algorithm after this many iterations\n",
    "    tolerance = 0.01               # We conclude convergence when the magnitude of the gradient\n",
    "                                   # is less than the tolerance\n",
    "    \n",
    "    while convergence == 0:\n",
    "        ####################### MISSING PART ############## \n",
    "        # Compute gradient and take a step in the direction it dictates\n",
    "        \n",
    "        \n",
    "        \n",
    "        ####################### MISSING PART ##############        \n",
    "        # Check for convergence -- you need to fill in the computation of the norm of the gradient at the current location\n",
    "        num_iter = num_iter + 1      \n",
    "        #cur_grad_norm = ##### MISSING\n",
    "        \n",
    "        if cur_grad_norm < tolerance:\n",
    "            convergence = 1\n",
    "            print('converged')\n",
    "        elif num_iter > max_iter:\n",
    "            convergence = 1 \n",
    "            print('reached maximum nr of iterations')\n",
    "    \n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run your code to return your resulting A, B and A*B, and compare it with M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
