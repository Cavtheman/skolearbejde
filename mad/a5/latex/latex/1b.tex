First we will find the values of $\alpha$ and $\beta$. We don't have a proper method to do so, but will look at it piecewise and realise that for this value of $p(r)$ it is trivial. Whenever we write an expression regarding $p(r)$ it is assumed that it is the following segment: $p(r), (0 \leq r \leq 1)$
$$
p(r) = 2r = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} r^{\alpha-1}(1-r)^{\beta-1}
$$
We can realise that the following part will always be a constant multiplier on $r$:
$$
\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}
$$
This means we have to solve the following:
$$
\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} = 2
$$
We can also realise that the latter part will always result in an exponent to $r$:
$$
r^{\alpha-1}(1-r)^{\beta-1}
$$
This means we have to solve the following:
$$
r^{\alpha-1}(1-r)^{\beta-1} = r
$$
We find that the values $\alpha = 2,\beta = 1$ fit all these criteria:
$$
\frac{\Gamma(2 + 1)}{\Gamma(2)\Gamma(1)} r^{2-1}(1-r)^{1-1} = 2r
$$
For calculating the posterior, we can reuse much of the math from $1(a)$. We can realise that $p(y_N|r)$ is the same since it is not dependent on $p(r)$. The other two functions only have small changes:
$$
p(r|y_N) = \frac{p(y_N|r)p(r)}{p(y_N)}
$$
$$
p(r) = 2r
$$
$$
p(y_N|r) = \begin{pmatrix} N\\ y_N \end{pmatrix} r^{y_N} (1-r)^{N-y_N}
$$
$$
p(y_N) = \int^{r=1}_{r=0} p(y_N|r)p(r)dr = \int^{r=1}_{r=0} 2r\begin{pmatrix} N\\ y_N \end{pmatrix} r^{y_N} (1-r)^{N-y_N}dr
$$
We use the same assumption as in the last exercise:
$$
\int^{r=1}_{r=0}r^{\alpha-1}(1-r)^{\beta-1}dr = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}
$$
And rewrite:
$$
p(y_N) = 2\begin{pmatrix} N\\ y_N \end{pmatrix} \int^{r=1}_{r=0} r * r^{y_N} (1-r)^{N-y_N}dr
$$
$$
p(y_N) = 2\begin{pmatrix} N\\ y_N \end{pmatrix} \int^{r=1}_{r=0} r^{y_N+1} (1-r)^{N-y_N}dr
$$
We substitute again, with $k = y_N+2$ and $t=N-y_N+1$
$$
p(y_N) = 2\begin{pmatrix} N\\ y_N \end{pmatrix} \int^{r=1}_{r=0} r^{k-1} (1-r)^{t-1}dr
$$
We can now solve it as per the assumption above:
$$
p(y_N) = 2\begin{pmatrix} N\\ y_N \end{pmatrix} \frac{\Gamma(y_N+2)\Gamma(N-y_N+1)}{\Gamma(y_N+2 + N-y_N+1)} = 2\begin{pmatrix} N\\ y_N \end{pmatrix} \frac{\Gamma(y_N+2)\Gamma(N-y_N+1)}{\Gamma(N+3)}
$$
We can now put everything into the original expression again:
$$
p(r|y_N) = \frac{p(y_N|r)p(r)}{p(y_N)} = \frac{2r\begin{pmatrix} N\\ y_N \end{pmatrix} r^{y_N} (1-r)^{N-y_N}}{2\begin{pmatrix} N\\ y_N \end{pmatrix} \frac{\Gamma(y_N+2)\Gamma(N-y_N+1)}{\Gamma(N+3)}}
$$
$$
p(r|y_N) = \frac{p(y_N|r)p(r)}{p(y_N)} = \frac{2\begin{pmatrix} N\\ y_N \end{pmatrix} r^{y_N+1} (1-r)^{N-y_N}}{2\begin{pmatrix} N\\ y_N \end{pmatrix} \frac{\Gamma(y_N+2)\Gamma(N-y_N+1)}{\Gamma(N+3)}}
$$
$$
p(r|y_N) = \frac{p(y_N|r)p(r)}{p(y_N)} = \frac{r^{y_N+1} (1-r)^{N-y_N}}{\Big(\frac{\Gamma(y_N+2)\Gamma(N-y_N+1)}{\Gamma(N+3)}\Big)}
$$
We rewrite the denominator so that we instead multiply by the inverse:
$$
p(r|y_N) = \frac{\Gamma(N+3)}{\Gamma(y_N+2)\Gamma(N-y_N+1)}r^{y_N+1} (1-r)^{N-y_N}
$$
We can now see that this is a beta density distribution.