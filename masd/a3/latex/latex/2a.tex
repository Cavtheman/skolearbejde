Mathematically, the model calculates the length of a matrix norm, usually filled with very small numbers. The matrices $A$ and $B$ are defined early on as matrices that, when multiplied together, form a matrix very similar to $M$, but with more values where $M$ has zeroes. These values in which $M$ has a zero value, but $AB$ has a value are basically predictions for what they would be in $M$, if the dataset was complete. When multiplying by $I$ however, these values are negated, since we don't need them to check accuracy. Since $AB$ and $M$ are so close to each other, we are going to get very small values in the resulting matrix when we say $M-AB$. When we calculate the matrix norm of the resulting matrix, we are essentially adding all of the differences together, to check whether they are inside a predetermined threshold. Adding them all together and squaring them allows the algorithm to easily check for an average error rate. But if even one value in $AB$ is significantly off, the error value that the function returns will become large easily.

The two matrices $A$ and $B$ can be seen as how much each person likes a genre, and how much a film scores in a specific genre respectively. In this case, there are only two general genres, which is why $A$ and $B$ are of the form $(6\times 2)$ and $(2\times 10)$. In this case with the Netflix problem, multiplying a persons like of a particular genre with how much the film scores in that particular genre, continuing to do this for all genres and adding it all together gives a good guess at how much a person would like a movie they haven't seen before.